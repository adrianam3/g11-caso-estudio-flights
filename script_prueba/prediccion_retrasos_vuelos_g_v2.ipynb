{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d544edea",
   "metadata": {},
   "source": [
    "# Predicci√≥n de Retrasos de Vuelos: Comparativa de Estrategias y Modelos (v5)\n",
    "\n",
    "**Objetivo:** Comparar de forma justa m√∫ltiples estrategias de *feature engineering* y m√∫ltiples modelos para encontrar la mejor combinaci√≥n para predecir retrasos de vuelos (`RETRASADO_LLEGADA`).\n",
    "\n",
    "**Metodolog√≠a de Validaci√≥n:**\n",
    "Para evitar fuga de datos (data leakage), se usar√° un **Split Temporal**:\n",
    "- **Train:** Meses 1‚Äì9\n",
    "- **Valid:** Meses 10‚Äì12\n",
    "\n",
    "**Experimentos:**\n",
    "1.  **Comparativa de Features (con LGBM):**\n",
    "    - **Exp 1:** LabelEncoder (Simple)\n",
    "    - **Exp 2:** Target Encoding (Avanzado)\n",
    "    - **Exp 3:** Target Encoding + Agregados Hist√≥ricos (M√°s Avanzado)\n",
    "2.  **Batalla de Modelos (con las mejores features):**\n",
    "    - LightGBM\n",
    "    - XGBoost\n",
    "    - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d049bb",
   "metadata": {},
   "source": [
    "2: Importaciones y Configuraci√≥n Global (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcc9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_recall_curve, auc as sk_auc\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- Configuraci√≥n Global ---\n",
    "# ¬°¬°IMPORTANTE!! Ajusta esta ruta a tu archivo local\n",
    "DATA_PATH = r\"D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\data\\processed\\flights_clean.csv\"\n",
    "\n",
    "TARGET_COL = \"RETRASADO_LLEGADA\"\n",
    "RESULTS = [] # Aqu√≠ se guardar√°n los resultados de cada modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e8868",
   "metadata": {},
   "source": [
    "3: Paso 1 - Carga y Preparaci√≥n de Datos (Helpers) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecc29c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\data\\processed\\flights_clean.csv...\n",
      "Datos preparados. Shape: (5231130, 25)\n",
      "Realizando split temporal (Train 1-9, Valid 10-12)...\n",
      "X_train: (4299046, 24), X_valid: (932084, 24)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 1: FUNCIONES DE PREPARACI√ìN DE DATOS (Helpers)\n",
    "# ==============================================================================\n",
    "\n",
    "def load_and_prep_data(data_path):\n",
    "    \"\"\"Carga y deriva todas las features necesarias del CSV.\"\"\"\n",
    "    print(f\"Cargando datos desde {data_path}...\")\n",
    "    \n",
    "    # Columnas que necesitamos del CSV original\n",
    "    need_cols = [\n",
    "        \"MONTH\", \"DAY_OF_WEEK\", \"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\",\n",
    "        \"SCHEDULED_DEPARTURE\", \"SCHEDULED_ARRIVAL\", \n",
    "        \"SCHEDULED_TIME\", \"DISTANCE\",\n",
    "        \"ORIGEN_LAT\", \"ORIGEN_LON\", \"DEST_LAT\", \"DEST_LON\",\n",
    "        \"SALIDA_SIN\", \"SALIDA_COS\", \"LLEGADA_SIN\", \"LLEGADA_COS\",\n",
    "        \"RETRASADO_LLEGADA\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        header = pd.read_csv(data_path, nrows=0).columns.tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontr√≥ el archivo en {data_path}\")\n",
    "        return None\n",
    "        \n",
    "    present = [c for c in need_cols if c in header]\n",
    "    \n",
    "    # Definir tipos de datos para ahorrar memoria\n",
    "    dtype_map = {\n",
    "        \"MONTH\":\"int8\", \"DAY_OF_WEEK\":\"int8\", \"AIRLINE\":\"category\", \n",
    "        \"ORIGIN_AIRPORT\":\"category\", \"DESTINATION_AIRPORT\":\"category\",\n",
    "        \"SCHEDULED_DEPARTURE\":\"int32\", \"SCHEDULED_ARRIVAL\":\"int32\",\n",
    "        \"SCHEDULED_TIME\":\"float32\", \"DISTANCE\":\"float32\",\n",
    "        \"ORIGEN_LAT\":\"float32\", \"ORIGEN_LON\":\"float32\",\n",
    "        \"DEST_LAT\":\"float32\", \"DEST_LON\":\"float32\", \n",
    "        \"SALIDA_SIN\":\"float32\", \"SALIDA_COS\":\"float32\", \n",
    "        \"LLEGADA_SIN\":\"float32\", \"LLEGADA_COS\":\"float32\",\n",
    "        \"RETRASADO_LLEGADA\":\"int8\"\n",
    "    }\n",
    "    dtype_eff = {k:v for k,v in dtype_map.items() if k in present}\n",
    "\n",
    "    v = pd.read_csv(data_path, usecols=present, dtype=dtype_eff, low_memory=False)\n",
    "\n",
    "    # --- Derivar features FALTANTES (si no vinieron en el CSV) ---\n",
    "    \n",
    "    def haversine_km(lat1, lon1, lat2, lon2):\n",
    "        R = 6371.0\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1; dlon = lon2 - lon1\n",
    "        a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "        return (2*R*np.arcsin(np.sqrt(a))).astype(np.float32)\n",
    "\n",
    "    if \"DISTANCIA_HAV\" not in v.columns and \"DISTANCE\" not in v.columns:\n",
    "        if {\"ORIGEN_LAT\", \"ORIGEN_LON\", \"DEST_LAT\", \"DEST_LON\"}.issubset(v.columns):\n",
    "            v[\"DISTANCIA_HAV\"] = haversine_km(v[\"ORIGEN_LAT\"], v[\"ORIGEN_LON\"], v[\"DEST_LAT\"], v[\"DEST_LON\"])\n",
    "        else:\n",
    "            v[\"DISTANCIA_HAV\"] = 0.0\n",
    "    elif \"DISTANCE\" in v.columns and \"DISTANCIA_HAV\" not in v.columns:\n",
    "        v[\"DISTANCIA_HAV\"] = v[\"DISTANCE\"].astype(\"float32\") \n",
    "\n",
    "    if \"SCHEDULED_TIME\" not in v.columns: v[\"SCHEDULED_TIME\"] = 0.0\n",
    "        \n",
    "    if \"MINUTO_DIA_SALIDA\" not in v.columns and \"SCHEDULED_DEPARTURE\" in v.columns:\n",
    "        hs = (v[\"SCHEDULED_DEPARTURE\"] // 100).clip(0, 23).astype(\"int16\")\n",
    "        ms = (v[\"SCHEDULED_DEPARTURE\"] % 100).clip(0, 59).astype(\"int16\")\n",
    "        v[\"MINUTO_DIA_SALIDA\"] = (hs * 60 + ms).astype(\"int16\")\n",
    "        v[\"HORA_SALIDA\"] = hs\n",
    "    \n",
    "    if \"SALIDA_SIN\" not in v.columns and \"MINUTO_DIA_SALIDA\" in v.columns:\n",
    "        rad = 2*np.pi*(v[\"MINUTO_DIA_SALIDA\"].astype(float)/(24*60))\n",
    "        v[\"SALIDA_SIN\"] = np.sin(rad).astype(\"float32\")\n",
    "        v[\"SALIDA_COS\"] = np.cos(rad).astype(\"float32\")\n",
    "\n",
    "    if \"MINUTO_DIA_LLEGADA\" not in v.columns and \"SCHEDULED_ARRIVAL\" in v.columns:\n",
    "        hl = (v[\"SCHEDULED_ARRIVAL\"] // 100).clip(0, 23).astype(\"int16\")\n",
    "        ml = (v[\"SCHEDULED_ARRIVAL\"] % 100).clip(0, 59).astype(\"int16\")\n",
    "        v[\"MINUTO_DIA_LLEGADA\"] = (hl * 60 + ml).astype(\"int16\")\n",
    "    \n",
    "    if \"LLEGADA_SIN\" not in v.columns and \"MINUTO_DIA_LLEGADA\" in v.columns:\n",
    "        rad_l = 2*np.pi*(v[\"MINUTO_DIA_LLEGADA\"].astype(float)/(24*60))\n",
    "        v[\"LLEGADA_SIN\"] = np.sin(rad_l).astype(\"float32\")\n",
    "        v[\"LLEGADA_COS\"] = np.cos(rad_l).astype(\"float32\")\n",
    "        \n",
    "    if \"MONTH_SIN\" not in v.columns and \"MONTH\" in v.columns:\n",
    "        v[\"MONTH_SIN\"] = np.sin(2*np.pi * v[\"MONTH\"]/12).astype(\"float32\")\n",
    "        v[\"MONTH_COS\"] = np.cos(2*np.pi * v[\"MONTH\"]/12).astype(\"float32\")\n",
    "\n",
    "    if \"RUTA\" not in v.columns:\n",
    "        v[\"RUTA\"] = v[\"ORIGIN_AIRPORT\"].astype(str) + \"_\" + v[\"DESTINATION_AIRPORT\"].astype(str)\n",
    "    \n",
    "    print(f\"Datos preparados. Shape: {v.shape}\")\n",
    "    return v\n",
    "\n",
    "def split_temporal(df, target_col):\n",
    "    \"\"\"Split temporal: Train 1-9, Valid 10-12\"\"\"\n",
    "    print(\"Realizando split temporal (Train 1-9, Valid 10-12)...\")\n",
    "    train_mask = df[\"MONTH\"].between(1, 9)\n",
    "    valid_mask = df[\"MONTH\"].between(10, 12)\n",
    "    \n",
    "    y = df[target_col].astype(\"int8\")\n",
    "    X = df.drop(columns=[target_col])\n",
    "    \n",
    "    X_train, y_train = X.loc[train_mask].copy(), y.loc[train_mask].copy()\n",
    "    X_valid, y_valid = X.loc[valid_mask].copy(), y.loc[valid_mask].copy()\n",
    "    \n",
    "    print(f\"X_train: {X_train.shape}, X_valid: {X_valid.shape}\")\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "# Ejecutar carga y split\n",
    "v_full = load_and_prep_data(DATA_PATH)\n",
    "if v_full is not None:\n",
    "    X_train_base, y_train_base, X_valid_base, y_valid_base = split_temporal(v_full, TARGET_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454bf7a",
   "metadata": {},
   "source": [
    "4: Paso 2 - Funciones de Feature Engineering (Codificadores) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feb0060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASO 2: FUNCIONES DE FEATURE ENGINEERING (Codificadores)\n",
    "# ==============================================================================\n",
    "\n",
    "def apply_label_encoder(X_train_subset, X_valid_subset):\n",
    "    \"\"\"Aplica LabelEncoder y maneja categor√≠as desconocidas.\"\"\"\n",
    "    print(\"Aplicando LabelEncoder...\")\n",
    "    X_train_le = X_train_subset.copy()\n",
    "    X_valid_le = X_valid_subset.copy()\n",
    "    cat_cols_in_subset = X_train_subset.columns \n",
    "    encoders = {}\n",
    "    \n",
    "    for col in cat_cols_in_subset: \n",
    "        le = LabelEncoder()\n",
    "        X_train_le[col] = le.fit_transform(X_train_le[col].astype(str))\n",
    "        \n",
    "        le_classes = set(le.classes_)\n",
    "        X_valid_le[col] = X_valid_le[col].astype(str).apply(lambda x: x if x in le_classes else '<unknown>')\n",
    "        if '<unknown>' not in le_classes:\n",
    "            le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "        \n",
    "        X_valid_le[col] = le.transform(X_valid_le[col])\n",
    "        encoders[col] = le\n",
    "            \n",
    "    return X_train_le, X_valid_le, encoders\n",
    "\n",
    "def kfold_target_encode(s_train, y_train, s_valid, smoothing=50):\n",
    "    \"\"\"Helper para TE K-Fold (sin fuga) en una columna.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    gmean = float(y_train.mean())\n",
    "    enc_train = pd.Series(index=s_train.index, dtype=\"float32\")\n",
    "\n",
    "    for tr_idx, val_idx in skf.split(s_train, y_train):\n",
    "        s_tr, y_tr = s_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "        s_val = s_train.iloc[val_idx]\n",
    "\n",
    "        stats = y_tr.groupby(s_tr.astype(str)).mean()\n",
    "        cnts = y_tr.groupby(s_tr.astype(str)).size()\n",
    "        smoothed = ((stats * cnts + gmean * smoothing) / (cnts + smoothing)).to_dict()\n",
    "        enc_train.iloc[val_idx] = s_val.astype(str).map(smoothed).fillna(gmean)\n",
    "\n",
    "    full_stats = y_train.groupby(s_train.astype(str)).mean()\n",
    "    full_cnts = y_train.groupby(s_train.astype(str)).size()\n",
    "    mapping = ((full_stats * full_cnts + gmean * smoothing) / (full_cnts + smoothing)).to_dict()\n",
    "    enc_valid = s_valid.astype(str).map(mapping).fillna(gmean).astype(\"float32\")\n",
    "    \n",
    "    return enc_train.astype(\"float32\"), enc_valid\n",
    "\n",
    "def apply_target_encoding(X_train, y_train, X_valid, cat_cols):\n",
    "    \"\"\"Aplica TE K-Fold y DEVUELVE SOLO LAS NUEVAS COLUMNAS (preserva √≠ndice).\"\"\"\n",
    "    print(\"Aplicando Target Encoding K-Fold...\")\n",
    "    X_train_te = pd.DataFrame(index=X_train.index)\n",
    "    X_valid_te = pd.DataFrame(index=X_valid.index)\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        new_col_name = f\"{col}_TE\"\n",
    "        enc_tr, enc_val = kfold_target_encode(X_train[col], y_train, X_valid[col])\n",
    "        X_train_te[new_col_name] = enc_tr\n",
    "        X_valid_te[new_col_name] = enc_val\n",
    "        \n",
    "    return X_train_te, X_valid_te\n",
    "\n",
    "# ================================================================\n",
    "# *** VERSI√ìN CORREGIDA (v7) de apply_historical_aggs ***\n",
    "# ================================================================\n",
    "def apply_historical_aggs(X_train, y_train, X_valid, agg_specs):\n",
    "    \"\"\"\n",
    "    Calcula agregados hist√≥ricos y DEVUELVE SOLO LAS NUEVAS COLUMNAS.\n",
    "    (v7 FIX: Reindexa el merge al √≠ndice original)\n",
    "    \"\"\"\n",
    "    print(\"Aplicando Agregados Hist√≥ricos (v7 Fix)...\")\n",
    "    gmean = float(y_train.mean())\n",
    "    \n",
    "    X_train_agg_cols = pd.DataFrame(index=X_train.index)\n",
    "    X_valid_agg_cols = pd.DataFrame(index=X_valid.index)\n",
    "\n",
    "    df_train = X_train.copy()\n",
    "    df_train[TARGET_COL] = y_train\n",
    "    \n",
    "    for keys, pref in agg_specs:\n",
    "        rate_col, n_col = f\"{pref}_rate\", f\"{pref}_n\"\n",
    "        \n",
    "        # 1. Calcular stats *solo* en train\n",
    "        agg = df_train.groupby(keys, observed=True)[TARGET_COL].agg([\"mean\", \"size\"]).reset_index()\n",
    "        agg.columns = keys + [rate_col, n_col]\n",
    "        \n",
    "        # 2. Aplicar (mapear) stats a X_train y X_valid\n",
    "        #    Preservamos el √≠ndice original haciendo el merge sobre el √≠ndice\n",
    "        X_train_merged = X_train[keys].merge(agg, on=keys, how=\"left\")\n",
    "        X_valid_merged = X_valid[keys].merge(agg, on=keys, how=\"left\")\n",
    "\n",
    "        # 3. *** FIX ***\n",
    "        # El merge desordena el √≠ndice. Debemos re-alinearlo al √≠ndice original\n",
    "        # de X_train/X_valid ANTES de llenar NaNs y asignar.\n",
    "        X_train_merged.index = X_train.index\n",
    "        X_valid_merged.index = X_valid.index\n",
    "\n",
    "        # 4. Llenar NaNs y asignar (ahora los √≠ndices coinciden)\n",
    "        X_train_agg_cols[rate_col] = X_train_merged[rate_col].fillna(gmean).astype(\"float32\")\n",
    "        X_train_agg_cols[n_col] = X_train_merged[n_col].fillna(0).astype(\"float32\")\n",
    "        X_valid_agg_cols[rate_col] = X_valid_merged[rate_col].fillna(gmean).astype(\"float32\")\n",
    "        X_valid_agg_cols[n_col] = X_valid_merged[n_col].fillna(0).astype(\"float32\")\n",
    "\n",
    "    return X_train_agg_cols, X_valid_agg_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1436ad9",
   "metadata": {},
   "source": [
    "Celda 5: Paso 3 - Funciones de Entrenamiento (LGBM, XGB, RF) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef90b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASO 3: FUNCIONES DE ENTRENAMIENTO Y EVALUACI√ìN (CORREGIDO v16)\n",
    "# ==============================================================================\n",
    "\n",
    "def find_best_f1_threshold(y_true, y_proba):\n",
    "    \"\"\"Encuentra el umbral que maximiza el F1-Score.\"\"\"\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9) # Evitar divisi√≥n por cero\n",
    "    best_f1_idx = np.nanargmax(f1s)\n",
    "    # Asegurar que el √≠ndice no est√© fuera de los l√≠mites de thr\n",
    "    if best_f1_idx < len(thr):\n",
    "        return f1s[best_f1_idx], thr[best_f1_idx]\n",
    "    else:\n",
    "        # Fallback si el mejor F1 est√° en el √∫ltimo punto (sin umbral)\n",
    "        return f1s[best_f1_idx], 0.99\n",
    "    \n",
    "\n",
    "def train_lgbm(X_train, y_train, X_valid, y_valid, exp_name, categorical_features=None):\n",
    "    \"\"\"Entrena LGBM y reporta m√©tricas.\"\"\"\n",
    "    print(f\"\\n--- Entrenando Experimento: {exp_name} (LGBM) ---\")\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'n_estimators': 1000, \n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 127,\n",
    "        'class_weight': 'balanced', # Usar esto\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'min_child_samples': 200\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    fit_params = {\n",
    "        \"eval_set\": [(X_valid, y_valid)],\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"callbacks\": [lgb.early_stopping(100), lgb.log_evaluation(200)]\n",
    "    }\n",
    "    \n",
    "    # *** FIX v16 (LGBM) ***\n",
    "    # Si usamos LabelEncoder (Exp 1), solo pasamos los NOMBRES.\n",
    "    # La conversi√≥n a Dtype 'category' se hace AFUERA (en la Celda 7).\n",
    "    if categorical_features:\n",
    "        fit_params[\"categorical_feature\"] = categorical_features\n",
    "        \n",
    "    model.fit(X_train, y_train, **fit_params) # X_train/y_train ya est√°n alineados\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {t1-t0:.1f}s (Best iter: {model.best_iteration_})\\n\")\n",
    "    \n",
    "    y_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_valid, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_valid, y_proba)\n",
    "    auc_pr = sk_auc(rec, prec)\n",
    "    best_f1, best_thr = find_best_f1_threshold(y_valid, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Modelo\": \"LGBM\",\n",
    "        \"Experimento\": exp_name,\n",
    "        \"ROC-AUC\": round(auc_roc, 4),\n",
    "        \"PR-AUC\": round(auc_pr, 4),\n",
    "        \"Best_F1\": round(best_f1, 4),\n",
    "        \"Best_F1_Threshold\": round(best_thr, 3),\n",
    "        \"Tiempo (s)\": round(t1 - t0, 1)\n",
    "    }\n",
    "    RESULTS.append(metrics)\n",
    "    return model, metrics\n",
    "\n",
    "def train_xgb(X_train, y_train, X_valid, y_valid, exp_name, categorical_features=None):\n",
    "    \"\"\"Entrena XGBoost y reporta m√©tricas.\"\"\"\n",
    "    print(f\"\\n--- Entrenando Experimento: {exp_name} (XGBoost) ---\")\n",
    "    \n",
    "    neg = (y_train == 0).sum()\n",
    "    pos = (y_train == 1).sum()\n",
    "    scale_pos_weight = neg / pos\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 8, \n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'min_child_weight': 5,\n",
    "        'early_stopping_rounds': 100 # v14 fix\n",
    "    }\n",
    "    \n",
    "    # *** FIX v16 (XGB) ***\n",
    "    # La conversi√≥n a Dtype 'category' se hace AFUERA (en la Celda 7).\n",
    "    if categorical_features:\n",
    "        params['enable_categorical'] = True\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=200\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {t1-t0:.1f}s (Best iter: {model.best_iteration})\\n\")\n",
    "    \n",
    "    y_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_valid, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_valid, y_proba)\n",
    "    auc_pr = sk_auc(rec, prec)\n",
    "    best_f1, best_thr = find_best_f1_threshold(y_valid, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Modelo\": \"XGBoost\",\n",
    "        \"Experimento\": exp_name,\n",
    "        \"ROC-AUC\": round(auc_roc, 4),\n",
    "        \"PR-AUC\": round(auc_pr, 4),\n",
    "        \"Best_F1\": round(best_f1, 4),\n",
    "        \"Best_F1_Threshold\": round(best_thr, 3),\n",
    "        \"Tiempo (s)\": round(t1 - t0, 1)\n",
    "    }\n",
    "    RESULTS.append(metrics)\n",
    "    return model, metrics\n",
    "\n",
    "def train_rf(X_train, y_train, X_valid, y_valid, exp_name):\n",
    "    \"\"\"Entrena Random Forest y reporta m√©tricas.\"\"\"\n",
    "    print(f\"\\n--- Entrenando Experimento: {exp_name} (RandomForest) ---\")\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': 100, # Reducido para velocidad\n",
    "        'max_depth': 20, \n",
    "        'min_samples_leaf': 100, \n",
    "        'max_features': 'sqrt',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {t1-t0:.1f}s\\n\")\n",
    "    \n",
    "    y_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_valid, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_valid, y_proba)\n",
    "    auc_pr = sk_auc(rec, prec)\n",
    "    best_f1, best_thr = find_best_f1_threshold(y_valid, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Modelo\": \"RandomForest\",\n",
    "        \"Experimento\": exp_name,\n",
    "        \"ROC-AUC\": round(auc_roc, 4),\n",
    "        \"PR-AUC\": round(auc_pr, 4),\n",
    "        \"Best_F1\": round(best_f1, 4),\n",
    "        \"Best_F1_Threshold\": round(best_thr, 3),\n",
    "        \"Tiempo (s)\": round(t1 - t0, 1)\n",
    "    }\n",
    "    RESULTS.append(metrics)\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a49e0",
   "metadata": {},
   "source": [
    "6: Paso 4 - Ejecuci√≥n de Experimentos (Setup) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e1bf259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 10 features num√©ricas y 4 categ√≥ricas.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 4: PREPARACI√ìN DE VARIABLES BASE\n",
    "# ==============================================================================\n",
    "\n",
    "# Columnas para ingenier√≠a de features\n",
    "cat_cols = [\"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\", \"RUTA\"]\n",
    "num_cols = [\n",
    "    \"MONTH\", \"DAY_OF_WEEK\", \n",
    "    \"SALIDA_SIN\", \"SALIDA_COS\", \n",
    "    \"LLEGADA_SIN\", \"LLEGADA_COS\",\n",
    "    \"MONTH_SIN\", \"MONTH_COS\",\n",
    "    \"SCHEDULED_TIME\", \"DISTANCIA_HAV\" \n",
    "]\n",
    "# Filtrar por las que realmente existen en v_full\n",
    "num_cols = [c for c in num_cols if c in v_full.columns]\n",
    "cat_cols = [c for c in cat_cols if c in v_full.columns]\n",
    "\n",
    "agg_specs = [\n",
    "    ([\"RUTA\", \"HORA_SALIDA\"], \"RUTA_HORA\"),\n",
    "    ([\"AIRLINE\"], \"AIR\"),\n",
    "    ([\"ORIGIN_AIRPORT\"], \"ORI\"),\n",
    "    ([\"DESTINATION_AIRPORT\"], \"DES\")\n",
    "]\n",
    "\n",
    "# --- Targets reseteados (se usan en todos los experimentos) ---\n",
    "y_train_r = y_train_base.reset_index(drop=True)\n",
    "y_valid_r = y_valid_base.reset_index(drop=True)\n",
    "\n",
    "# Guardar las matrices num√©ricas base (con √≠ndice reseteado)\n",
    "X_train_num_r = X_train_base[num_cols].reset_index(drop=True)\n",
    "X_valid_num_r = X_valid_base[num_cols].reset_index(drop=True)\n",
    "\n",
    "print(f\"Usando {len(num_cols)} features num√©ricas y {len(cat_cols)} categ√≥ricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a63e40",
   "metadata": {},
   "source": [
    "7: Experimento 1 (LabelEncoder) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ed2aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO EXPERIMENTO 1: LabelEncoder ===\n",
      "Aplicando LabelEncoder...\n",
      "\n",
      "--- Entrenando Experimento: Exp 1: LabelEncoder (LGBM) ---\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 805372, number of negative: 3493674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5871\n",
      "[LightGBM] [Info] Number of data points in the train set: 4299046, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.615217\n",
      "Entrenamiento completado en 89.0s (Best iter: 71)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 1: LabelEncoder (XGBoost) ---\n",
      "[0]\tvalidation_0-auc:0.57678\n",
      "[166]\tvalidation_0-auc:0.61389\n",
      "Entrenamiento completado en 112.9s (Best iter: 67)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 1: LabelEncoder (RandomForest) ---\n",
      "Entrenamiento completado en 248.5s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                        min_samples_leaf=100, n_jobs=-1, random_state=42),\n",
       " {'Modelo': 'RandomForest',\n",
       "  'Experimento': 'Exp 1: LabelEncoder',\n",
       "  'ROC-AUC': 0.6155,\n",
       "  'PR-AUC': 0.2344,\n",
       "  'Best_F1': np.float64(0.3297),\n",
       "  'Best_F1_Threshold': np.float64(0.425),\n",
       "  'Tiempo (s)': 248.5})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Exp 1: LabelEncoder --- \n",
    "# ==============================================================================\n",
    "print(\"\\n=== INICIANDO EXPERIMENTO 1: LabelEncoder ===\")\n",
    "\n",
    "# 1. Aplicar LE\n",
    "X_train_le, X_valid_le, le_encoders = apply_label_encoder(X_train_base[cat_cols], X_valid_base[cat_cols])\n",
    "\n",
    "# 2. Unir num√©ricas (reseteadas) + LE (reseteadas)\n",
    "X_train_1 = pd.concat([X_train_num_r, X_train_le.reset_index(drop=True)], axis=1)\n",
    "X_valid_1 = pd.concat([X_valid_num_r, X_valid_le.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 3. Nombres de las columnas categ√≥ricas\n",
    "cat_features_names = list(X_train_le.columns)\n",
    "\n",
    "# 4. *** FIX v16 (LGBM/XGB) ***\n",
    "# Crear copias para convertir a Dtype 'category' UNIFICADO\n",
    "# Esto es necesario ANTES de llamar a .fit()\n",
    "X_train_1_cat = X_train_1.copy()\n",
    "X_valid_1_cat = X_valid_1.copy()\n",
    "\n",
    "for col in cat_features_names:\n",
    "    # 1. Crear tipo unificado (de train Y valid)\n",
    "    all_cats = pd.concat([X_train_1_cat[col], X_valid_1_cat[col]]).unique()\n",
    "    cat_type = pd.CategoricalDtype(categories=all_cats, ordered=False)\n",
    "    # 2. Aplicar a ambos\n",
    "    X_train_1_cat[col] = X_train_1_cat[col].astype(cat_type)\n",
    "    X_valid_1_cat[col] = X_valid_1_cat[col].astype(cat_type)\n",
    "    \n",
    "# 5. Entrenar Modelos\n",
    "# (Pasamos X/y reseteados (0..N) y las versiones _cat para LGBM/XGB)\n",
    "train_lgbm(X_train_1_cat, y_train_r, X_valid_1_cat, y_valid_r, \"Exp 1: LabelEncoder\", categorical_features=cat_features_names)\n",
    "train_xgb(X_train_1_cat, y_train_r, X_valid_1_cat, y_valid_r, \"Exp 1: LabelEncoder\", categorical_features=cat_features_names)\n",
    "\n",
    "# RF prefiere los ints simples (X_train_1)\n",
    "train_rf(X_train_1, y_train_r, X_valid_1, y_valid_r, \"Exp 1: LabelEncoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094404c6",
   "metadata": {},
   "source": [
    "8: Experimento 2 (Target Encoding) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "407495d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO EXPERIMENTO 2: Target Encoding ===\n",
      "Aplicando Target Encoding K-Fold...\n",
      "\n",
      "--- Entrenando Experimento: Exp 2: TargetEncoding (LGBM) ---\n",
      "[LightGBM] [Info] Number of positive: 805372, number of negative: 3493674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2398\n",
      "[LightGBM] [Info] Number of data points in the train set: 4299046, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.611184\n",
      "[400]\tvalid_0's auc: 0.612138\n",
      "[600]\tvalid_0's auc: 0.61272\n",
      "[800]\tvalid_0's auc: 0.612675\n",
      "Early stopping, best iteration is:\n",
      "[704]\tvalid_0's auc: 0.612817\n",
      "Entrenamiento completado en 229.1s (Best iter: 704)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 2: TargetEncoding (XGBoost) ---\n",
      "[0]\tvalidation_0-auc:0.59016\n",
      "[200]\tvalidation_0-auc:0.61278\n",
      "[400]\tvalidation_0-auc:0.61316\n",
      "[600]\tvalidation_0-auc:0.61335\n",
      "[678]\tvalidation_0-auc:0.61331\n",
      "Entrenamiento completado en 397.0s (Best iter: 579)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 2: TargetEncoding (RandomForest) ---\n",
      "Entrenamiento completado en 331.7s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                        min_samples_leaf=100, n_jobs=-1, random_state=42),\n",
       " {'Modelo': 'RandomForest',\n",
       "  'Experimento': 'Exp 2: TargetEncoding',\n",
       "  'ROC-AUC': 0.6204,\n",
       "  'PR-AUC': 0.2415,\n",
       "  'Best_F1': np.float64(0.3316),\n",
       "  'Best_F1_Threshold': np.float64(0.423),\n",
       "  'Tiempo (s)': 331.7})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Exp 2: Target Encoding --- \n",
    "# ==============================================================================\n",
    "print(\"\\n=== INICIANDO EXPERIMENTO 2: Target Encoding ===\")\n",
    "\n",
    "# 1. Aplicar TE\n",
    "# (y_train e y_valid tienen el √≠ndice original, alineado con X_train_base)\n",
    "# X_train_te_cols y X_valid_te_cols tienen el √≠ndice original (0, 1, 5, 8...)\n",
    "X_train_te_cols, X_valid_te_cols = apply_target_encoding(X_train_base[cat_cols], y_train_base, X_valid_base[cat_cols], cat_cols)\n",
    "\n",
    "# 2. Unir num√©ricas (reseteadas 0..N) + TE (reseteadas 0..N)\n",
    "X_train_2 = pd.concat([X_train_num_r, X_train_te_cols.reset_index(drop=True)], axis=1)\n",
    "X_valid_2 = pd.concat([X_valid_num_r, X_valid_te_cols.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 3. Entrenar Modelos (sin categorical_features, ya que TE es num√©rico)\n",
    "train_lgbm(X_train_2, y_train_r, X_valid_2, y_valid_r, \"Exp 2: TargetEncoding\")\n",
    "train_xgb(X_train_2, y_train_r, X_valid_2, y_valid_r, \"Exp 2: TargetEncoding\")\n",
    "train_rf(X_train_2, y_train_r, X_valid_2, y_valid_r, \"Exp 2: TargetEncoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c580a09",
   "metadata": {},
   "source": [
    "9: Experimento 3 (Target Encoding + Agregados) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8dcdaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO EXPERIMENTO 3: TE + Agregados Hist√≥ricos ===\n",
      "Aplicando Agregados Hist√≥ricos (v7 Fix)...\n",
      "\n",
      "--- Entrenando Experimento: Exp 3: TE + Agregados (LGBM) ---\n",
      "[LightGBM] [Info] Number of positive: 805372, number of negative: 3493674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3686\n",
      "[LightGBM] [Info] Number of data points in the train set: 4299046, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.608403\n",
      "Entrenamiento completado en 58.6s (Best iter: 5)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 3: TE + Agregados (XGBoost) ---\n",
      "[0]\tvalidation_0-auc:0.59705\n",
      "[175]\tvalidation_0-auc:0.60222\n",
      "Entrenamiento completado en 123.5s (Best iter: 76)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 3: TE + Agregados (RandomForest) ---\n",
      "Entrenamiento completado en 402.9s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                        min_samples_leaf=100, n_jobs=-1, random_state=42),\n",
       " {'Modelo': 'RandomForest',\n",
       "  'Experimento': 'Exp 3: TE + Agregados',\n",
       "  'ROC-AUC': 0.6079,\n",
       "  'PR-AUC': 0.2356,\n",
       "  'Best_F1': np.float64(0.324),\n",
       "  'Best_F1_Threshold': np.float64(0.391),\n",
       "  'Tiempo (s)': 402.9})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Exp 3: TE + Agregados --- \n",
    "# ==============================================================================\n",
    "print(\"\\n=== INICIANDO EXPERIMENTO 3: TE + Agregados Hist√≥ricos ===\")\n",
    "\n",
    "# 1. Calcular Agregados (preservan √≠ndice original 0, 1, 5, 8...)\n",
    "X_train_agg_cols, X_valid_agg_cols = apply_historical_aggs(X_train_base, y_train_base, X_valid_base, agg_specs)\n",
    "\n",
    "# 2. X_train_te_cols ya existe del paso anterior (con √≠ndice original 0, 1, 5, 8...)\n",
    "\n",
    "# 3. Unir num√©ricas (reseteadas) + TE (reseteadas) + Agregados (reseteados)\n",
    "X_train_3 = pd.concat([\n",
    "    X_train_num_r, \n",
    "    X_train_te_cols.reset_index(drop=True), # Reseteado (0..N)\n",
    "    X_train_agg_cols.reset_index(drop=True) # Reseteado (0..N)\n",
    "], axis=1)\n",
    "\n",
    "X_valid_3 = pd.concat([\n",
    "    X_valid_num_r, \n",
    "    X_valid_te_cols.reset_index(drop=True), # Reseteado (0..N)\n",
    "    X_valid_agg_cols.reset_index(drop=True) # Reseteado (0..N)\n",
    "], axis=1)\n",
    "\n",
    "# 4. Entrenar Modelos\n",
    "train_lgbm(X_train_3, y_train_r, X_valid_3, y_valid_r, \"Exp 3: TE + Agregados\")\n",
    "train_xgb(X_train_3, y_train_r, X_valid_3, y_valid_r, \"Exp 3: TE + Agregados\")\n",
    "train_rf(X_train_3, y_train_r, X_valid_3, y_valid_r, \"Exp 3: TE + Agregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc36f3",
   "metadata": {},
   "source": [
    "10: Paso 5 - Reporte Final (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b2c645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Comparaci√≥n Final de Alternativas (Validadas en Meses 10-12) ---\n",
      "|                                           |   ROC-AUC |   PR-AUC |   Best_F1 |   Best_F1_Threshold |   Tiempo (s) |\n",
      "|:------------------------------------------|----------:|---------:|----------:|--------------------:|-------------:|\n",
      "| ('Exp 2: TargetEncoding', 'RandomForest') |    0.6204 |   0.2415 |    0.3316 |              0.4230 |     331.7000 |\n",
      "| ('Exp 1: LabelEncoder', 'XGBoost')        |    0.6161 |   0.2360 |    0.3297 |              0.3900 |     112.9000 |\n",
      "| ('Exp 1: LabelEncoder', 'RandomForest')   |    0.6155 |   0.2344 |    0.3297 |              0.4250 |     248.5000 |\n",
      "| ('Exp 1: LabelEncoder', 'LGBM')           |    0.6152 |   0.2353 |    0.3299 |              0.3710 |      89.0000 |\n",
      "| ('Exp 2: TargetEncoding', 'XGBoost')      |    0.6135 |   0.2371 |    0.3276 |              0.3450 |     397.0000 |\n",
      "| ('Exp 1: LabelEncoder', 'LGBM')           |    0.6135 |   0.2334 |    0.3296 |              0.3890 |     131.8000 |\n",
      "| ('Exp 1: LabelEncoder', 'LGBM')           |    0.6135 |   0.2334 |    0.3296 |              0.3890 |     391.2000 |\n",
      "| ('Exp 1: LabelEncoder', 'LGBM')           |    0.6135 |   0.2334 |    0.3296 |              0.3890 |     123.2000 |\n",
      "| ('Exp 2: TargetEncoding', 'LGBM')         |    0.6128 |   0.2351 |    0.3280 |              0.3590 |     229.1000 |\n",
      "| ('Exp 3: TE + Agregados', 'LGBM')         |    0.6084 |   0.2309 |    0.3255 |              0.4840 |      58.6000 |\n",
      "| ('Exp 3: TE + Agregados', 'RandomForest') |    0.6079 |   0.2356 |    0.3240 |              0.3910 |     402.9000 |\n",
      "| ('Exp 3: TE + Agregados', 'XGBoost')      |    0.6027 |   0.2283 |    0.3218 |              0.3680 |     123.5000 |\n",
      "\n",
      "üèÜ Ganador (por ROC-AUC): Exp 2: TargetEncoding con RandomForest (AUC: 0.6204)\n",
      "---\n",
      "Nota: Un ROC-AUC m√°s alto es mejor para distinguir clases (ranking general).\n",
      "Un PR-AUC m√°s alto es mejor para encontrar retrasos (desbalanceado).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 6: REPORTE FINAL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\\n--- Comparaci√≥n Final de Alternativas (Validadas en Meses 10-12) ---\")\n",
    "df_results = pd.DataFrame(RESULTS).set_index([\"Experimento\", \"Modelo\"])\n",
    "\n",
    "# Ordenar por la mejor m√©trica (ROC-AUC y luego PR-AUC)\n",
    "df_sorted = df_results.sort_values(by=[\"ROC-AUC\", \"PR-AUC\"], ascending=False)\n",
    "\n",
    "# Imprimir como markdown para f√°cil lectura\n",
    "print(df_sorted.to_markdown(floatfmt=\".4f\"))\n",
    "\n",
    "# Determinar el ganador\n",
    "if not df_sorted.empty:\n",
    "    winner_exp = df_sorted.index[0][0]\n",
    "    winner_model = df_sorted.index[0][1]\n",
    "    winner_auc = df_sorted.iloc[0][\"ROC-AUC\"]\n",
    "    print(f\"\\nüèÜ Ganador (por ROC-AUC): {winner_exp} con {winner_model} (AUC: {winner_auc:.4f})\")\n",
    "else:\n",
    "    print(\"\\nNo se completaron experimentos para determinar un ganador.\")\n",
    "print(\"---\")\n",
    "print(\"Nota: Un ROC-AUC m√°s alto es mejor para distinguir clases (ranking general).\")\n",
    "print(\"Un PR-AUC m√°s alto es mejor para encontrar retrasos (desbalanceado).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
