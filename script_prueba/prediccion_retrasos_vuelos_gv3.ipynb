{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a056e89c",
   "metadata": {},
   "source": [
    "Celda 6 (Paso 4), donde a√±adimos DEPARTURE_DELAY a la lista num_cols, y la Celda 3 (Paso 1) para asegurarnos de que se carga esa columna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f745150",
   "metadata": {},
   "source": [
    "Celda 1: T√≠tulo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c803ee5",
   "metadata": {},
   "source": [
    "# Predicci√≥n de Retrasos de Vuelos: Comparativa de Modelos (v17)\n",
    "\n",
    "**Objetivo:** Comparar estrategias de *feature engineering* y modelos para predecir retrasos en la llegada, **incluyendo `DEPARTURE_DELAY`** como feature.\n",
    "\n",
    "**Metodolog√≠a de Validaci√≥n:**\n",
    "- **Train:** Meses 1‚Äì9\n",
    "- **Valid:** Meses 10‚Äì12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b0da6",
   "metadata": {},
   "source": [
    "\n",
    "Celda 2: Importaciones y Configuraci√≥n Global (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_recall_curve, auc as sk_auc\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- Configuraci√≥n Global ---\n",
    "# ¬°¬°IMPORTANTE!! Ajusta esta ruta a tu archivo local\n",
    "DATA_PATH = r\"D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\data\\processed\\flights_clean.csv\"\n",
    "\n",
    "TARGET_COL = \"RETRASADO_LLEGADA\"\n",
    "RESULTS = [] # Aqu√≠ se guardar√°n los resultados de cada modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49332b1f",
   "metadata": {},
   "source": [
    "Celda 3: Paso 1 - Carga y Preparaci√≥n de Datos (Helpers) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\data\\processed\\flights_clean.csv...\n",
      "Datos preparados. Shape: (5231130, 26)\n",
      "Realizando split temporal (Train 1-9, Valid 10-12)...\n",
      "X_train: (4299046, 25), X_valid: (932084, 25)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 1: FUNCIONES DE PREPARACI√ìN DE DATOS (Helpers)\n",
    "# ==============================================================================\n",
    "\n",
    "def load_and_prep_data(data_path):\n",
    "    \"\"\"Carga y deriva todas las features necesarias del CSV.\"\"\"\n",
    "    print(f\"Cargando datos desde {data_path}...\")\n",
    "    \n",
    "    # Columnas que necesitamos del CSV original\n",
    "    need_cols = [\n",
    "        \"MONTH\", \"DAY_OF_WEEK\", \"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\",\n",
    "        \"SCHEDULED_DEPARTURE\", \"SCHEDULED_ARRIVAL\", \n",
    "        \"SCHEDULED_TIME\", \"DISTANCE\",\n",
    "        \"ORIGEN_LAT\", \"ORIGEN_LON\", \"DEST_LAT\", \"DEST_LON\",\n",
    "        \"SALIDA_SIN\", \"SALIDA_COS\", \"LLEGADA_SIN\", \"LLEGADA_COS\",\n",
    "        \"DEPARTURE_DELAY\", # <<<--- ¬°¬°A√ëADIDO!!\n",
    "        \"RETRASADO_LLEGADA\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        header = pd.read_csv(data_path, nrows=0).columns.tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontr√≥ el archivo en {data_path}\")\n",
    "        return None\n",
    "        \n",
    "    present = [c for c in need_cols if c in header]\n",
    "    \n",
    "    # Definir tipos de datos para ahorrar memoria\n",
    "    dtype_map = {\n",
    "        \"MONTH\":\"int8\", \"DAY_OF_WEEK\":\"int8\", \"AIRLINE\":\"category\", \n",
    "        \"ORIGIN_AIRPORT\":\"category\", \"DESTINATION_AIRPORT\":\"category\",\n",
    "        \"SCHEDULED_DEPARTURE\":\"int32\", \"SCHEDULED_ARRIVAL\":\"int32\",\n",
    "        \"SCHEDULED_TIME\":\"float32\", \"DISTANCE\":\"float32\",\n",
    "        \"ORIGEN_LAT\":\"float32\", \"ORIGEN_LON\":\"float32\",\n",
    "        \"DEST_LAT\":\"float32\", \"DEST_LON\":\"float32\", \n",
    "        \"SALIDA_SIN\":\"float32\", \"SALIDA_COS\":\"float32\", \n",
    "        \"LLEGADA_SIN\":\"float32\", \"LLEGADA_COS\":\"float32\",\n",
    "        \"DEPARTURE_DELAY\":\"float32\", # <<<--- ¬°¬°A√ëADIDO!!\n",
    "        \"RETRASADO_LLEGADA\":\"int8\"\n",
    "    }\n",
    "    dtype_eff = {k:v for k,v in dtype_map.items() if k in present}\n",
    "\n",
    "    v = pd.read_csv(data_path, usecols=present, dtype=dtype_eff, low_memory=False)\n",
    "\n",
    "    # --- Derivar features FALTANTES (si no vinieron en el CSV) ---\n",
    "    \n",
    "    def haversine_km(lat1, lon1, lat2, lon2):\n",
    "        R = 6371.0\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1; dlon = lon2 - lon1\n",
    "        a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "        return (2*R*np.arcsin(np.sqrt(a))).astype(np.float32)\n",
    "\n",
    "    if \"DISTANCIA_HAV\" not in v.columns and \"DISTANCE\" not in v.columns:\n",
    "        if {\"ORIGEN_LAT\", \"ORIGEN_LON\", \"DEST_LAT\", \"DEST_LON\"}.issubset(v.columns):\n",
    "            v[\"DISTANCIA_HAV\"] = haversine_km(v[\"ORIGEN_LAT\"], v[\"ORIGEN_LON\"], v[\"DEST_LAT\"], v[\"DEST_LON\"])\n",
    "        else:\n",
    "            v[\"DISTANCIA_HAV\"] = 0.0\n",
    "    elif \"DISTANCE\" in v.columns and \"DISTANCIA_HAV\" not in v.columns:\n",
    "        v[\"DISTANCIA_HAV\"] = v[\"DISTANCE\"].astype(\"float32\") \n",
    "\n",
    "    if \"SCHEDULED_TIME\" not in v.columns: v[\"SCHEDULED_TIME\"] = 0.0\n",
    "        \n",
    "    if \"MINUTO_DIA_SALIDA\" not in v.columns and \"SCHEDULED_DEPARTURE\" in v.columns:\n",
    "        hs = (v[\"SCHEDULED_DEPARTURE\"] // 100).clip(0, 23).astype(\"int16\")\n",
    "        ms = (v[\"SCHEDULED_DEPARTURE\"] % 100).clip(0, 59).astype(\"int16\")\n",
    "        v[\"MINUTO_DIA_SALIDA\"] = (hs * 60 + ms).astype(\"int16\")\n",
    "        v[\"HORA_SALIDA\"] = hs\n",
    "    \n",
    "    if \"SALIDA_SIN\" not in v.columns and \"MINUTO_DIA_SALIDA\" in v.columns:\n",
    "        rad = 2*np.pi*(v[\"MINUTO_DIA_SALIDA\"].astype(float)/(24*60))\n",
    "        v[\"SALIDA_SIN\"] = np.sin(rad).astype(\"float32\")\n",
    "        v[\"SALIDA_COS\"] = np.cos(rad).astype(\"float32\")\n",
    "\n",
    "    if \"MINUTO_DIA_LLEGADA\" not in v.columns and \"SCHEDULED_ARRIVAL\" in v.columns:\n",
    "        hl = (v[\"SCHEDULED_ARRIVAL\"] // 100).clip(0, 23).astype(\"int16\")\n",
    "        ml = (v[\"SCHEDULED_ARRIVAL\"] % 100).clip(0, 59).astype(\"int16\")\n",
    "        v[\"MINUTO_DIA_LLEGADA\"] = (hl * 60 + ml).astype(\"int16\")\n",
    "    \n",
    "    if \"LLEGADA_SIN\" not in v.columns and \"MINUTO_DIA_LLEGADA\" in v.columns:\n",
    "        rad_l = 2*np.pi*(v[\"MINUTO_DIA_LLEGADA\"].astype(float)/(24*60))\n",
    "        v[\"LLEGADA_SIN\"] = np.sin(rad_l).astype(\"float32\")\n",
    "        v[\"LLEGADA_COS\"] = np.cos(rad_l).astype(\"float32\")\n",
    "        \n",
    "    if \"MONTH_SIN\" not in v.columns and \"MONTH\" in v.columns:\n",
    "        v[\"MONTH_SIN\"] = np.sin(2*np.pi * v[\"MONTH\"]/12).astype(\"float32\")\n",
    "        v[\"MONTH_COS\"] = np.cos(2*np.pi * v[\"MONTH\"]/12).astype(\"float32\")\n",
    "\n",
    "    if \"RUTA\" not in v.columns:\n",
    "        v[\"RUTA\"] = v[\"ORIGIN_AIRPORT\"].astype(str) + \"_\" + v[\"DESTINATION_AIRPORT\"].astype(str)\n",
    "        \n",
    "    # --- Manejar NaNs en DEPARTURE_DELAY (importante) ---\n",
    "    if \"DEPARTURE_DELAY\" in v.columns:\n",
    "        v[\"DEPARTURE_DELAY\"] = v[\"DEPARTURE_DELAY\"].fillna(0).astype(\"float32\")\n",
    "    else:\n",
    "        v[\"DEPARTURE_DELAY\"] = 0.0 # Placeholder si falta\n",
    "    \n",
    "    print(f\"Datos preparados. Shape: {v.shape}\")\n",
    "    return v\n",
    "\n",
    "def split_temporal(df, target_col):\n",
    "    \"\"\"Split temporal: Train 1-9, Valid 10-12\"\"\"\n",
    "    print(\"Realizando split temporal (Train 1-9, Valid 10-12)...\")\n",
    "    train_mask = df[\"MONTH\"].between(1, 9)\n",
    "    valid_mask = df[\"MONTH\"].between(10, 12)\n",
    "    \n",
    "    y = df[target_col].astype(\"int8\")\n",
    "    X = df.drop(columns=[target_col])\n",
    "    \n",
    "    X_train, y_train = X.loc[train_mask].copy(), y.loc[train_mask].copy()\n",
    "    X_valid, y_valid = X.loc[valid_mask].copy(), y.loc[valid_mask].copy()\n",
    "    \n",
    "    print(f\"X_train: {X_train.shape}, X_valid: {X_valid.shape}\")\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "# Ejecutar carga y split\n",
    "v_full = load_and_prep_data(DATA_PATH)\n",
    "if v_full is not None:\n",
    "    X_train_base, y_train_base, X_valid_base, y_valid_base = split_temporal(v_full, TARGET_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae52720",
   "metadata": {},
   "source": [
    "Celda 4: Paso 2 - Funciones de Feature Engineering (Codificadores) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ae6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASO 2: FUNCIONES DE FEATURE ENGINEERING (Codificadores)\n",
    "# ==============================================================================\n",
    "\n",
    "def apply_label_encoder(X_train_subset, X_valid_subset):\n",
    "    \"\"\"Aplica LabelEncoder y maneja categor√≠as desconocidas.\"\"\"\n",
    "    print(\"Aplicando LabelEncoder...\")\n",
    "    X_train_le = X_train_subset.copy()\n",
    "    X_valid_le = X_valid_subset.copy()\n",
    "    cat_cols_in_subset = X_train_subset.columns \n",
    "    encoders = {}\n",
    "    \n",
    "    for col in cat_cols_in_subset: \n",
    "        le = LabelEncoder()\n",
    "        X_train_le[col] = le.fit_transform(X_train_le[col].astype(str))\n",
    "        \n",
    "        le_classes = set(le.classes_)\n",
    "        X_valid_le[col] = X_valid_le[col].astype(str).apply(lambda x: x if x in le_classes else '<unknown>')\n",
    "        if '<unknown>' not in le_classes:\n",
    "            le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "        \n",
    "        X_valid_le[col] = le.transform(X_valid_le[col])\n",
    "        encoders[col] = le\n",
    "            \n",
    "    return X_train_le, X_valid_le, encoders\n",
    "\n",
    "def kfold_target_encode(s_train, y_train, s_valid, smoothing=50):\n",
    "    \"\"\"Helper para TE K-Fold (sin fuga) en una columna.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    gmean = float(y_train.mean())\n",
    "    enc_train = pd.Series(index=s_train.index, dtype=\"float32\")\n",
    "\n",
    "    for tr_idx, val_idx in skf.split(s_train, y_train):\n",
    "        s_tr, y_tr = s_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "        s_val = s_train.iloc[val_idx]\n",
    "\n",
    "        stats = y_tr.groupby(s_tr.astype(str)).mean()\n",
    "        cnts = y_tr.groupby(s_tr.astype(str)).size()\n",
    "        smoothed = ((stats * cnts + gmean * smoothing) / (cnts + smoothing)).to_dict()\n",
    "        enc_train.iloc[val_idx] = s_val.astype(str).map(smoothed).fillna(gmean)\n",
    "\n",
    "    full_stats = y_train.groupby(s_train.astype(str)).mean()\n",
    "    full_cnts = y_train.groupby(s_train.astype(str)).size()\n",
    "    mapping = ((full_stats * full_cnts + gmean * smoothing) / (full_cnts + smoothing)).to_dict()\n",
    "    enc_valid = s_valid.astype(str).map(mapping).fillna(gmean).astype(\"float32\")\n",
    "    \n",
    "    return enc_train.astype(\"float32\"), enc_valid\n",
    "\n",
    "def apply_target_encoding(X_train, y_train, X_valid, cat_cols):\n",
    "    \"\"\"Aplica TE K-Fold y DEVUELVE SOLO LAS NUEVAS COLUMNAS (preserva √≠ndice).\"\"\"\n",
    "    print(\"Aplicando Target Encoding K-Fold...\")\n",
    "    X_train_te = pd.DataFrame(index=X_train.index)\n",
    "    X_valid_te = pd.DataFrame(index=X_valid.index)\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        new_col_name = f\"{col}_TE\"\n",
    "        enc_tr, enc_val = kfold_target_encode(X_train[col], y_train, X_valid[col])\n",
    "        X_train_te[new_col_name] = enc_tr\n",
    "        X_valid_te[new_col_name] = enc_val\n",
    "        \n",
    "    return X_train_te, X_valid_te\n",
    "\n",
    "def apply_historical_aggs(X_train, y_train, X_valid, agg_specs):\n",
    "    \"\"\"\n",
    "    Calcula agregados hist√≥ricos y DEVUELVE SOLO LAS NUEVAS COLUMNAS.\n",
    "    (v7 FIX: Reindexa el merge al √≠ndice original)\n",
    "    \"\"\"\n",
    "    print(\"Aplicando Agregados Hist√≥ricos (v7 Fix)...\")\n",
    "    gmean = float(y_train.mean())\n",
    "    \n",
    "    X_train_agg_cols = pd.DataFrame(index=X_train.index)\n",
    "    X_valid_agg_cols = pd.DataFrame(index=X_valid.index)\n",
    "\n",
    "    df_train = X_train.copy()\n",
    "    df_train[TARGET_COL] = y_train\n",
    "    \n",
    "    for keys, pref in agg_specs:\n",
    "        rate_col, n_col = f\"{pref}_rate\", f\"{pref}_n\"\n",
    "        \n",
    "        # 1. Calcular stats *solo* en train\n",
    "        agg = df_train.groupby(keys, observed=True)[TARGET_COL].agg([\"mean\", \"size\"]).reset_index()\n",
    "        agg.columns = keys + [rate_col, n_col]\n",
    "        \n",
    "        # 2. Aplicar (mapear) stats a X_train y X_valid\n",
    "        #    Preservamos el √≠ndice original haciendo el merge sobre el √≠ndice\n",
    "        X_train_merged = X_train[keys].merge(agg, on=keys, how=\"left\")\n",
    "        X_valid_merged = X_valid[keys].merge(agg, on=keys, how=\"left\")\n",
    "\n",
    "        # 3. *** FIX ***\n",
    "        # El merge desordena el √≠ndice. Debemos re-alinearlo al √≠ndice original\n",
    "        # de X_train/X_valid ANTES de llenar NaNs y asignar.\n",
    "        X_train_merged.index = X_train.index\n",
    "        X_valid_merged.index = X_valid.index\n",
    "\n",
    "        # 4. Llenar NaNs y asignar (ahora los √≠ndices coinciden)\n",
    "        X_train_agg_cols[rate_col] = X_train_merged[rate_col].fillna(gmean).astype(\"float32\")\n",
    "        X_train_agg_cols[n_col] = X_train_merged[n_col].fillna(0).astype(\"float32\")\n",
    "        X_valid_agg_cols[rate_col] = X_valid_merged[rate_col].fillna(gmean).astype(\"float32\")\n",
    "        X_valid_agg_cols[n_col] = X_valid_merged[n_col].fillna(0).astype(\"float32\")\n",
    "\n",
    "    return X_train_agg_cols, X_valid_agg_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c412520",
   "metadata": {},
   "source": [
    "Celda 5: Paso 3 - Funciones de Entrenamiento (LGBM, XGB, RF) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b228bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASO 3: FUNCIONES DE ENTRENAMIENTO Y EVALUACI√ìN (CORREGIDO v16)\n",
    "# ==============================================================================\n",
    "\n",
    "def find_best_f1_threshold(y_true, y_proba):\n",
    "    \"\"\"Encuentra el umbral que maximiza el F1-Score.\"\"\"\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9) # Evitar divisi√≥n por cero\n",
    "    best_f1_idx = np.nanargmax(f1s)\n",
    "    # Asegurar que el √≠ndice no est√© fuera de los l√≠mites de thr\n",
    "    if best_f1_idx < len(thr):\n",
    "        return f1s[best_f1_idx], thr[best_f1_idx]\n",
    "    else:\n",
    "        # Fallback si el mejor F1 est√° en el √∫ltimo punto (sin umbral)\n",
    "        return f1s[best_f1_idx], 0.99\n",
    "    \n",
    "\n",
    "def train_lgbm(X_train, y_train, X_valid, y_valid, exp_name, categorical_features=None):\n",
    "    \"\"\"Entrena LGBM y reporta m√©tricas.\"\"\"\n",
    "    print(f\"\\n--- Entrenando Experimento: {exp_name} (LGBM) ---\")\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'n_estimators': 1000, \n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 127,\n",
    "        'class_weight': 'balanced', # Usar esto\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'min_child_samples': 200\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    fit_params = {\n",
    "        \"eval_set\": [(X_valid, y_valid)],\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"callbacks\": [lgb.early_stopping(100), lgb.log_evaluation(200)]\n",
    "    }\n",
    "    \n",
    "    # *** FIX v16 (LGBM) ***\n",
    "    # Si usamos LabelEncoder (Exp 1), solo pasamos los NOMBRES.\n",
    "    # La conversi√≥n a Dtype 'category' se hace AFUERA (en la Celda 7).\n",
    "    if categorical_features:\n",
    "        fit_params[\"categorical_feature\"] = categorical_features\n",
    "        \n",
    "    model.fit(X_train, y_train, **fit_params) # X_train/y_train ya est√°n alineados\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {t1-t0:.1f}s (Best iter: {model.best_iteration_})\\n\")\n",
    "    \n",
    "    y_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_valid, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_valid, y_proba)\n",
    "    auc_pr = sk_auc(rec, prec)\n",
    "    best_f1, best_thr = find_best_f1_threshold(y_valid, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Modelo\": \"LGBM\",\n",
    "        \"Experimento\": exp_name,\n",
    "        \"ROC-AUC\": round(auc_roc, 4),\n",
    "        \"PR-AUC\": round(auc_pr, 4),\n",
    "        \"Best_F1\": round(best_f1, 4),\n",
    "        \"Best_F1_Threshold\": round(best_thr, 3),\n",
    "        \"Tiempo (s)\": round(t1 - t0, 1)\n",
    "    }\n",
    "    RESULTS.append(metrics)\n",
    "    return model, metrics\n",
    "\n",
    "def train_xgb(X_train, y_train, X_valid, y_valid, exp_name, categorical_features=None):\n",
    "    \"\"\"Entrena XGBoost y reporta m√©tricas.\"\"\"\n",
    "    print(f\"\\n--- Entrenando Experimento: {exp_name} (XGBoost) ---\")\n",
    "    \n",
    "    neg = (y_train == 0).sum()\n",
    "    pos = (y_train == 1).sum()\n",
    "    scale_pos_weight = neg / pos\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 8, \n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'min_child_weight': 5,\n",
    "        'early_stopping_rounds': 100 # v14 fix\n",
    "    }\n",
    "    \n",
    "    # *** FIX v16 (XGB) ***\n",
    "    # La conversi√≥n a Dtype 'category' se hace AFUERA (en la Celda 7).\n",
    "    if categorical_features:\n",
    "        params['enable_categorical'] = True\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=200\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {t1-t0:.1f}s (Best iter: {model.best_iteration})\\n\")\n",
    "    \n",
    "    y_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_valid, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_valid, y_proba)\n",
    "    auc_pr = sk_auc(rec, prec)\n",
    "    best_f1, best_thr = find_best_f1_threshold(y_valid, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Modelo\": \"XGBoost\",\n",
    "        \"Experimento\": exp_name,\n",
    "        \"ROC-AUC\": round(auc_roc, 4),\n",
    "        \"PR-AUC\": round(auc_pr, 4),\n",
    "        \"Best_F1\": round(best_f1, 4),\n",
    "        \"Best_F1_Threshold\": round(best_thr, 3),\n",
    "        \"Tiempo (s)\": round(t1 - t0, 1)\n",
    "    }\n",
    "    RESULTS.append(metrics)\n",
    "    return model, metrics\n",
    "\n",
    "def train_rf(X_train, y_train, X_valid, y_valid, exp_name):\n",
    "    \"\"\"Entrena Random Forest y reporta m√©tricas.\"\"\"\n",
    "    print(f\"\\n--- Entrenando Experimento: {exp_name} (RandomForest) ---\")\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': 100, # Reducido para velocidad\n",
    "        'max_depth': 20, \n",
    "        'min_samples_leaf': 100, \n",
    "        'max_features': 'sqrt',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {t1-t0:.1f}s\\n\")\n",
    "    \n",
    "    y_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_valid, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_valid, y_proba)\n",
    "    auc_pr = sk_auc(rec, prec)\n",
    "    best_f1, best_thr = find_best_f1_threshold(y_valid, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Modelo\": \"RandomForest\",\n",
    "        \"Experimento\": exp_name,\n",
    "        \"ROC-AUC\": round(auc_roc, 4),\n",
    "        \"PR-AUC\": round(auc_pr, 4),\n",
    "        \"Best_F1\": round(best_f1, 4),\n",
    "        \"Best_F1_Threshold\": round(best_thr, 3),\n",
    "        \"Tiempo (s)\": round(t1 - t0, 1)\n",
    "    }\n",
    "    RESULTS.append(metrics)\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6995094",
   "metadata": {},
   "source": [
    "Celda 6: Paso 4 - Preparaci√≥n de Variables Base (C√≥digo CORREGIDO)\n",
    "(Esta celda ahora incluye DEPARTURE_DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8dec6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 11 features num√©ricas (incluyendo DEPARTURE_DELAY) y 4 categ√≥ricas.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 4: PREPARACI√ìN DE VARIABLES BASE (v17 - con DEPARTURE_DELAY)\n",
    "# ==============================================================================\n",
    "\n",
    "# Columnas para ingenier√≠a de features\n",
    "cat_cols = [\"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\", \"RUTA\"]\n",
    "num_cols = [\n",
    "    \"MONTH\", \"DAY_OF_WEEK\", \n",
    "    \"SALIDA_SIN\", \"SALIDA_COS\", \n",
    "    \"LLEGADA_SIN\", \"LLEGADA_COS\",\n",
    "    \"MONTH_SIN\", \"MONTH_COS\",\n",
    "    \"SCHEDULED_TIME\", \"DISTANCIA_HAV\",\n",
    "    \"DEPARTURE_DELAY\"  # <<<--- ¬°¬°A√ëADIDO!!\n",
    "]\n",
    "# Filtrar por las que realmente existen en v_full\n",
    "num_cols = [c for c in num_cols if c in v_full.columns]\n",
    "cat_cols = [c for c in cat_cols if c in v_full.columns]\n",
    "\n",
    "agg_specs = [\n",
    "    ([\"RUTA\", \"HORA_SALIDA\"], \"RUTA_HORA\"),\n",
    "    ([\"AIRLINE\"], \"AIR\"),\n",
    "    ([\"ORIGIN_AIRPORT\"], \"ORI\"),\n",
    "    ([\"DESTINATION_AIRPORT\"], \"DES\")\n",
    "]\n",
    "\n",
    "# --- Targets reseteados (se usan en todos los experimentos) ---\n",
    "y_train_r = y_train_base.reset_index(drop=True)\n",
    "y_valid_r = y_valid_base.reset_index(drop=True)\n",
    "\n",
    "# Guardar las matrices num√©ricas base (con √≠ndice reseteado)\n",
    "X_train_num_r = X_train_base[num_cols].reset_index(drop=True)\n",
    "X_valid_num_r = X_valid_base[num_cols].reset_index(drop=True)\n",
    "\n",
    "print(f\"Usando {len(num_cols)} features num√©ricas (incluyendo DEPARTURE_DELAY) y {len(cat_cols)} categ√≥ricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08de2a2",
   "metadata": {},
   "source": [
    "Celda 7: Experimento 1 (LabelEncoder) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aab2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # --- Exp 1: LabelEncoder --- \n",
    "# # ==============================================================================\n",
    "# print(\"\\n=== INICIANDO EXPERIMENTO 1: LabelEncoder ===\")\n",
    "\n",
    "# # 1. Aplicar LE\n",
    "# X_train_le, X_valid_le, le_encoders = apply_label_encoder(X_train_base[cat_cols], X_valid_base[cat_cols])\n",
    "\n",
    "# # 2. Unir num√©ricas (reseteadas) + LE (reseteadas)\n",
    "# X_train_1 = pd.concat([X_train_num_r, X_train_le.reset_index(drop=True)], axis=1)\n",
    "# X_valid_1 = pd.concat([X_valid_num_r, X_valid_le.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# # 3. Nombres de las columnas categ√≥ricas\n",
    "# cat_features_names = list(X_train_le.columns)\n",
    "\n",
    "# # 4. *** FIX v16 (LGBM/XGB) ***\n",
    "# # Crear copias para convertir a Dtype 'category' UNIFICADO\n",
    "# X_train_1_cat = X_train_1.copy()\n",
    "# X_valid_1_cat = X_valid_1.copy()\n",
    "# for col in cat_features_names:\n",
    "#     all_cats = pd.concat([X_train_1_cat[col], X_valid_1_cat[col]]).unique()\n",
    "#     cat_type = pd.CategoricalDtype(categories=all_cats, ordered=False)\n",
    "#     X_train_1_cat[col] = X_train_1_cat[col].astype(cat_type)\n",
    "#     X_valid_1_cat[col] = X_valid_1_cat[col].astype(cat_type)\n",
    "    \n",
    "# # 5. Entrenar Modelos\n",
    "# # (Pasamos X/y reseteados (0..N) y las versiones _cat para LGBM/XGB)\n",
    "# train_lgbm(X_train_1_cat, y_train_r, X_valid_1_cat, y_valid_r, \"Exp 1: LabelEncoder\", categorical_features=cat_features_names)\n",
    "# train_xgb(X_train_1_cat, y_train_r, X_valid_1_cat, y_valid_r, \"Exp 1: LabelEncoder\", categorical_features=cat_features_names)\n",
    "# train_rf(X_train_1, y_train_r, X_valid_1, y_valid_r, \"Exp 1: LabelEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc56ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO EXPERIMENTO 1: LabelEncoder ===\n",
      "Aplicando LabelEncoder...\n",
      "\n",
      "--- Entrenando LGBM (Exp 1) ---\n",
      "\n",
      "--- Entrenando Experimento: Exp 1: LabelEncoder (LGBM) ---\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 805372, number of negative: 3493674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6126\n",
      "[LightGBM] [Info] Number of data points in the train set: 4299046, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.933111\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.934193\n",
      "Entrenamiento completado en 103.3s (Best iter: 107)\n",
      "\n",
      "\n",
      "--- Entrenando XGB (Exp 1) ---\n",
      "\n",
      "--- Entrenando Experimento: Exp 1: LabelEncoder (XGBoost) ---\n",
      "[0]\tvalidation_0-auc:0.92830\n",
      "[200]\tvalidation_0-auc:0.93400\n",
      "[248]\tvalidation_0-auc:0.93392\n",
      "Entrenamiento completado en 268.7s (Best iter: 148)\n",
      "\n",
      "\n",
      "--- Entrenando RF (Exp 1) ---\n",
      "\n",
      "--- Entrenando Experimento: Exp 1: LabelEncoder (RandomForest) ---\n",
      "Entrenamiento completado en 373.7s\n",
      "\n",
      "\n",
      "--- Variables capturadas para Exp 1 ---\n",
      "Modelo LGBM: <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "Encoders LE: <class 'dict'>\n",
      "M√©tricas LGBM: {'Modelo': 'LGBM', 'Experimento': 'Exp 1: LabelEncoder', 'ROC-AUC': 0.9342, 'PR-AUC': 0.8696, 'Best_F1': np.float64(0.7976), 'Best_F1_Threshold': np.float64(0.739), 'Tiempo (s)': 103.3}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Exp 1: LabelEncoder --- \n",
    "# ==============================================================================\n",
    "print(\"\\n=== INICIANDO EXPERIMENTO 1: LabelEncoder ===\")\n",
    "\n",
    "# 1. Aplicar LE\n",
    "# X_train_le e X_valid_le tienen el √≠ndice original\n",
    "X_train_le, X_valid_le, le_encoders = apply_label_encoder(X_train_base[cat_cols], X_valid_base[cat_cols])\n",
    "\n",
    "# 2. Unir num√©ricas (reseteadas) + LE (reseteadas)\n",
    "X_train_1 = pd.concat([X_train_num_r, X_train_le.reset_index(drop=True)], axis=1)\n",
    "X_valid_1 = pd.concat([X_valid_num_r, X_valid_le.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 3. Nombres de las columnas categ√≥ricas\n",
    "cat_features_names = list(X_train_le.columns)\n",
    "\n",
    "# 4. FIX v16 (LGBM/XGB)\n",
    "# Crear copias para convertir a Dtype 'category' UNIFICADO\n",
    "X_train_1_cat = X_train_1.copy()\n",
    "X_valid_1_cat = X_valid_1.copy()\n",
    "\n",
    "for col in cat_features_names:\n",
    "    all_cats = pd.concat([X_train_1_cat[col], X_valid_1_cat[col]]).unique()\n",
    "    cat_type = pd.CategoricalDtype(categories=all_cats, ordered=False)\n",
    "    X_train_1_cat[col] = X_train_1_cat[col].astype(cat_type)\n",
    "    X_valid_1_cat[col] = X_valid_1_cat[col].astype(cat_type)\n",
    "    \n",
    "# 5. Entrenar Modelos (¬°¬°AHORA CAPTURAMOS LAS VARIABLES!!)\n",
    "print(\"\\n--- Entrenando LGBM (Exp 1) ---\")\n",
    "lgbm_model_exp1, lgbm_metrics_exp1 = train_lgbm(\n",
    "    X_train_1_cat, y_train_r, X_valid_1_cat, y_valid_r, \n",
    "    \"Exp 1: LabelEncoder\", \n",
    "    categorical_features=cat_features_names\n",
    ")\n",
    "\n",
    "print(\"\\n--- Entrenando XGB (Exp 1) ---\")\n",
    "xgb_model_exp1, xgb_metrics_exp1 = train_xgb(\n",
    "    X_train_1_cat, y_train_r, X_valid_1_cat, y_valid_r, \n",
    "    \"Exp 1: LabelEncoder\", \n",
    "    categorical_features=cat_features_names\n",
    ")\n",
    "\n",
    "print(\"\\n--- Entrenando RF (Exp 1) ---\")\n",
    "rf_model_exp1, rf_metrics_exp1 = train_rf(\n",
    "    X_train_1, y_train_r, X_valid_1, y_valid_r, \n",
    "    \"Exp 1: LabelEncoder\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Variables capturadas para Exp 1 ---\")\n",
    "print(f\"Modelo LGBM: {type(lgbm_model_exp1)}\")\n",
    "print(f\"Encoders LE: {type(le_encoders)}\")\n",
    "print(f\"M√©tricas LGBM: {lgbm_metrics_exp1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c45e1c",
   "metadata": {},
   "source": [
    "Celda 7.1: Guardar Artefactos del Mejor Modelo (C√≥digo NUEVO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93064cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GUARDANDO ARTEFACTOS (Exp 1: LGBM + LabelEncoder) ===\n",
      "‚úì Modelo guardado en: D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\script_prueba\\models\\lgbm_classifier_exp1.joblib\n",
      "‚úì Encoders guardados en: D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\script_prueba\\models\\label_encoders_exp1.joblib\n",
      "‚úì Metadatos guardados en: D:\\OneDrive\\DOCUMENTOS\\Personales\\2024\\uniandes\\8 S\\seminario\\g11-caso-estudio-flights\\script_prueba\\models\\metadata_exp1.json\n",
      "\n",
      "--- Guardado completado ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 7.1: GUARDAR ARTEFACTOS DEL MEJOR MODELO (LGBM Exp 1)\n",
    "# ==============================================================================\n",
    "# Basado en los resultados de la Celda 10, el mejor modelo fue \n",
    "# \"Exp 1: LabelEncoder\" con \"LGBM\".\n",
    "# Usamos las variables capturadas en la Celda 7:\n",
    "# - lgbm_model_exp1 (el modelo)\n",
    "# - le_encoders (los encoders)\n",
    "# - X_train_1 (para la lista de features)\n",
    "# - lgbm_metrics_exp1 (las m√©tricas)\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n=== GUARDANDO ARTEFACTOS (Exp 1: LGBM + LabelEncoder) ===\")\n",
    "\n",
    "# --- 1. Definir Rutas (Estructura de machine_learning.ipynb) ---\n",
    "PROJECT_ROOT = Path(os.path.abspath(\"\")).resolve()\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Actualizamos los nombres para que coincidan con nuestro experimento\n",
    "ENCODER_PATH = MODELS_DIR / \"label_encoders_exp1.joblib\"\n",
    "MODEL_PATH = MODELS_DIR / \"lgbm_classifier_exp1.joblib\"\n",
    "METADATA_PATH = MODELS_DIR / \"metadata_exp1.json\"\n",
    "\n",
    "# --- 2. Validar que las variables existan ---\n",
    "try:\n",
    "    if 'lgbm_model_exp1' not in locals():\n",
    "        raise NameError(\"No se encontr√≥ 'lgbm_model_exp1'. Aseg√∫rate de ejecutar la Celda 7 (Exp 1) modificada.\")\n",
    "    if 'le_encoders' not in locals():\n",
    "        raise NameError(\"No se encontr√≥ 'le_encoders'. Aseg√∫rate de ejecutar la Celda 7 (Exp 1).\")\n",
    "    if 'X_train_1' not in locals():\n",
    "        raise NameError(\"No se encontr√≥ 'X_train_1' (para la lista de features).\")\n",
    "    if 'lgbm_metrics_exp1' not in locals():\n",
    "        raise NameError(\"No se encontr√≥ 'lgbm_metrics_exp1'.\")\n",
    "\n",
    "    # --- 3. Guardar los artefactos ---\n",
    "    \n",
    "    # Guardar el Modelo (LGBM)\n",
    "    # (Usamos joblib como en tu template)\n",
    "    joblib.dump(lgbm_model_exp1, MODEL_PATH)\n",
    "    print(f\"‚úì Modelo guardado en: {MODEL_PATH}\")\n",
    "    \n",
    "    # Guardar los Encoders (LabelEncoder dict)\n",
    "    # (Tu template usa joblib para el encoder, as√≠ que usamos joblib)\n",
    "    joblib.dump(le_encoders, ENCODER_PATH)\n",
    "    print(f\"‚úì Encoders guardados en: {ENCODER_PATH}\")\n",
    "    \n",
    "    # --- 4. Guardar Metadatos (Lista de Features y M√©tricas) ---\n",
    "    # (Usamos .json para esto porque es un dict simple)\n",
    "    metadata = {\n",
    "        \"model_path\": str(MODEL_PATH),\n",
    "        \"encoder_path\": str(ENCODER_PATH),\n",
    "        \"feature_order\": list(X_train_1.columns),\n",
    "        \"metrics_lgbm_exp1\": lgbm_metrics_exp1\n",
    "    }\n",
    "    \n",
    "    with open(METADATA_PATH, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"‚úì Metadatos guardados en: {METADATA_PATH}\")\n",
    "    \n",
    "    print(\"\\n--- Guardado completado ---\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"\\nERROR: Faltan variables necesarias para guardar.\")\n",
    "    print(e)\n",
    "    print(\"Por favor, aseg√∫rate de modificar y ejecutar la Celda 7 (Experimento 1) como se indic√≥.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1917fb",
   "metadata": {},
   "source": [
    "Celda 8: Experimento 2 (Target Encoding) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699fe33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO EXPERIMENTO 2: Target Encoding ===\n",
      "Aplicando Target Encoding K-Fold...\n",
      "\n",
      "--- Entrenando Experimento: Exp 2: TargetEncoding (LGBM) ---\n",
      "[LightGBM] [Info] Number of positive: 805372, number of negative: 3493674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2653\n",
      "[LightGBM] [Info] Number of data points in the train set: 4299046, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.933742\n",
      "[400]\tvalid_0's auc: 0.933958\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid_0's auc: 0.933985\n",
      "Entrenamiento completado en 156.3s (Best iter: 354)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 2: TargetEncoding (XGBoost) ---\n",
      "[0]\tvalidation_0-auc:0.92766\n",
      "[200]\tvalidation_0-auc:0.93337\n",
      "[400]\tvalidation_0-auc:0.93354\n",
      "[474]\tvalidation_0-auc:0.93334\n",
      "Entrenamiento completado en 246.0s (Best iter: 374)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 2: TargetEncoding (RandomForest) ---\n",
      "Entrenamiento completado en 302.3s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                        min_samples_leaf=100, n_jobs=-1, random_state=42),\n",
       " {'Modelo': 'RandomForest',\n",
       "  'Experimento': 'Exp 2: TargetEncoding',\n",
       "  'ROC-AUC': 0.9321,\n",
       "  'PR-AUC': 0.8647,\n",
       "  'Best_F1': np.float64(0.7974),\n",
       "  'Best_F1_Threshold': np.float64(0.758),\n",
       "  'Tiempo (s)': 302.3})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Exp 2: Target Encoding --- \n",
    "# ==============================================================================\n",
    "print(\"\\n=== INICIANDO EXPERIMENTO 2: Target Encoding ===\")\n",
    "\n",
    "# 1. Aplicar TE\n",
    "X_train_te_cols, X_valid_te_cols = apply_target_encoding(X_train_base[cat_cols], y_train_base, X_valid_base[cat_cols], cat_cols)\n",
    "\n",
    "# 2. Unir num√©ricas (reseteadas 0..N) + TE (reseteadas 0..N)\n",
    "X_train_2 = pd.concat([X_train_num_r, X_train_te_cols.reset_index(drop=True)], axis=1)\n",
    "X_valid_2 = pd.concat([X_valid_num_r, X_valid_te_cols.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 3. Entrenar Modelos (sin categorical_features, ya que TE es num√©rico)\n",
    "train_lgbm(X_train_2, y_train_r, X_valid_2, y_valid_r, \"Exp 2: TargetEncoding\")\n",
    "train_xgb(X_train_2, y_train_r, X_valid_2, y_valid_r, \"Exp 2: TargetEncoding\")\n",
    "train_rf(X_train_2, y_train_r, X_valid_2, y_valid_r, \"Exp 2: TargetEncoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de0b50",
   "metadata": {},
   "source": [
    "Celda 9: Experimento 3 (Target Encoding + Agregados) (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36367fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO EXPERIMENTO 3: TE + Agregados Hist√≥ricos ===\n",
      "Aplicando Agregados Hist√≥ricos (v7 Fix)...\n",
      "\n",
      "--- Entrenando Experimento: Exp 3: TE + Agregados (LGBM) ---\n",
      "[LightGBM] [Info] Number of positive: 805372, number of negative: 3493674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.369226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3941\n",
      "[LightGBM] [Info] Number of data points in the train set: 4299046, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.9319\n",
      "Entrenamiento completado en 56.8s (Best iter: 3)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 3: TE + Agregados (XGBoost) ---\n",
      "[0]\tvalidation_0-auc:0.92220\n",
      "[197]\tvalidation_0-auc:0.92839\n",
      "Entrenamiento completado en 122.7s (Best iter: 98)\n",
      "\n",
      "\n",
      "--- Entrenando Experimento: Exp 3: TE + Agregados (RandomForest) ---\n",
      "Entrenamiento completado en 366.1s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                        min_samples_leaf=100, n_jobs=-1, random_state=42),\n",
       " {'Modelo': 'RandomForest',\n",
       "  'Experimento': 'Exp 3: TE + Agregados',\n",
       "  'ROC-AUC': 0.9302,\n",
       "  'PR-AUC': 0.8583,\n",
       "  'Best_F1': np.float64(0.789),\n",
       "  'Best_F1_Threshold': np.float64(0.751),\n",
       "  'Tiempo (s)': 366.1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Exp 3: TE + Agregados --- \n",
    "# ==============================================================================\n",
    "print(\"\\n=== INICIANDO EXPERIMENTO 3: TE + Agregados Hist√≥ricos ===\")\n",
    "\n",
    "# 1. Calcular Agregados (preservan √≠ndice original 0, 1, 5, 8...)\n",
    "X_train_agg_cols, X_valid_agg_cols = apply_historical_aggs(X_train_base, y_train_base, X_valid_base, agg_specs)\n",
    "\n",
    "# 2. X_train_te_cols ya existe del paso anterior (con √≠ndice original 0, 1, 5, 8...)\n",
    "\n",
    "# 3. Unir num√©ricas (reseteadas) + TE (reseteadas) + Agregados (reseteados)\n",
    "X_train_3 = pd.concat([\n",
    "    X_train_num_r, \n",
    "    X_train_te_cols.reset_index(drop=True), # Reseteado (0..N)\n",
    "    X_train_agg_cols.reset_index(drop=True) # Reseteado (0..N)\n",
    "], axis=1)\n",
    "\n",
    "X_valid_3 = pd.concat([\n",
    "    X_valid_num_r, \n",
    "    X_valid_te_cols.reset_index(drop=True), # Reseteado (0..N)\n",
    "    X_valid_agg_cols.reset_index(drop=True) # Reseteado (0..N)\n",
    "], axis=1)\n",
    "\n",
    "# 4. Entrenar Modelos\n",
    "train_lgbm(X_train_3, y_train_r, X_valid_3, y_valid_r, \"Exp 3: TE + Agregados\")\n",
    "train_xgb(X_train_3, y_train_r, X_valid_3, y_valid_r, \"Exp 3: TE + Agregados\")\n",
    "train_rf(X_train_3, y_train_r, X_valid_3, y_valid_r, \"Exp 3: TE + Agregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40b582",
   "metadata": {},
   "source": [
    "Celda 10: Paso 6 - Reporte Final (C√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a969124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Comparaci√≥n Final de Alternativas (Validadas en Meses 10-12) ---\n",
      "|                                           |   ROC-AUC |   PR-AUC |   Best_F1 |   Best_F1_Threshold |   Tiempo (s) |\n",
      "|:------------------------------------------|----------:|---------:|----------:|--------------------:|-------------:|\n",
      "| ('Exp 1: LabelEncoder', 'LGBM')           |    0.9342 |   0.8696 |    0.7976 |              0.7390 |     135.6000 |\n",
      "| ('Exp 2: TargetEncoding', 'LGBM')         |    0.9340 |   0.8704 |    0.7980 |              0.7080 |     156.3000 |\n",
      "| ('Exp 1: LabelEncoder', 'XGBoost')        |    0.9339 |   0.8687 |    0.7939 |              0.7290 |     219.4000 |\n",
      "| ('Exp 2: TargetEncoding', 'XGBoost')      |    0.9336 |   0.8702 |    0.7980 |              0.7440 |     246.0000 |\n",
      "| ('Exp 1: LabelEncoder', 'RandomForest')   |    0.9335 |   0.8649 |    0.7978 |              0.7470 |     283.8000 |\n",
      "| ('Exp 2: TargetEncoding', 'RandomForest') |    0.9321 |   0.8647 |    0.7974 |              0.7580 |     302.3000 |\n",
      "| ('Exp 3: TE + Agregados', 'LGBM')         |    0.9319 |   0.8654 |    0.7959 |              0.5370 |      56.8000 |\n",
      "| ('Exp 3: TE + Agregados', 'XGBoost')      |    0.9302 |   0.8662 |    0.7957 |              0.7170 |     122.7000 |\n",
      "| ('Exp 3: TE + Agregados', 'RandomForest') |    0.9302 |   0.8583 |    0.7890 |              0.7510 |     366.1000 |\n",
      "\n",
      "üèÜ Ganador (por ROC-AUC): Exp 1: LabelEncoder con LGBM (AUC: 0.9342)\n",
      "---\n",
      "Nota: Un ROC-AUC m√°s alto es mejor para distinguir clases (ranking general).\n",
      "Un PR-AUC m√°s alto es mejor para encontrar retrasos (desbalanceado).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PASO 6: REPORTE FINAL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\\n--- Comparaci√≥n Final de Alternativas (Validadas en Meses 10-12) ---\")\n",
    "df_results = pd.DataFrame(RESULTS).set_index([\"Experimento\", \"Modelo\"])\n",
    "\n",
    "# Ordenar por la mejor m√©trica (ROC-AUC y luego PR-AUC)\n",
    "df_sorted = df_results.sort_values(by=[\"ROC-AUC\", \"PR-AUC\"], ascending=False)\n",
    "\n",
    "# Imprimir como markdown para f√°cil lectura\n",
    "print(df_sorted.to_markdown(floatfmt=\".4f\"))\n",
    "\n",
    "# Determinar el ganador\n",
    "if not df_sorted.empty:\n",
    "    winner_exp = df_sorted.index[0][0]\n",
    "    winner_model = df_sorted.index[0][1]\n",
    "    winner_auc = df_sorted.iloc[0][\"ROC-AUC\"]\n",
    "    print(f\"\\nüèÜ Ganador (por ROC-AUC): {winner_exp} con {winner_model} (AUC: {winner_auc:.4f})\")\n",
    "else:\n",
    "    print(\"\\nNo se completaron experimentos para determinar un ganador.\")\n",
    "print(\"---\")\n",
    "print(\"Nota: Un ROC-AUC m√°s alto es mejor para distinguir clases (ranking general).\")\n",
    "print(\"Un PR-AUC m√°s alto es mejor para encontrar retrasos (desbalanceado).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
